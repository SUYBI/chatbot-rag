from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.openai_like import OpenAILike
from llama_index.core.memory import ChatMemoryBuffer
from llama_index.core import Settings
#--------------------------------------------------------------------

import requests
from llama_index.core.llms import CustomLLM, CompletionResponse, LLMMetadata
from llama_index.core.llms.callbacks import llm_completion_callback
from typing import Any


ONEMINAI_API_KEY = "0b6ab860af35df8f5174d086c59ab072a2800664ceb36d12980366ae98ba654b"


class OneminAILLM(CustomLLM):
    model: str = "gpt-4o-mini"
    api_key: str = ONEMINAI_API_KEY
    api_base: str = "https://api.1min.ai/api/features"
    max_words: int = 2000
    temperature: float = 0.2

    @property
    def metadata(self) -> LLMMetadata:
        return LLMMetadata(
            model_name=self.model,
            context_window=8192,
            num_output=self.max_words,
            is_chat_model=True,
        )

    @llm_completion_callback()
    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:
        headers = {
            "Content-Type": "application/json",
            "API-KEY": self.api_key
        }

        payload = {
            "type": "CHAT_WITH_AI",
            "model": self.model,
            "promptObject": {
                "prompt": prompt,
                "isMixed": False,
                "webSearch": False
            }
        }

        try:
            response = requests.post(
                f"{self.api_base}?isStreaming=false",
                headers=headers,
                json=payload,
                timeout=400
            )

            if response.status_code != 200:
                raise ValueError(f"Erreur HTTP {response.status_code}: {response.text}")

            result = response.json()

            # â¬…ï¸ EXTRACTION CORRECTE BASÃ‰E SUR LA STRUCTURE RÃ‰ELLE
            text = result["aiRecord"]["aiRecordDetail"]["resultObject"][0]

            return CompletionResponse(text=text)

        except KeyError as e:
            print(f"âŒ Erreur d'extraction: clÃ© manquante {e}")
            print(f"Structure reÃ§ue: {result}")
            raise
        except Exception as e:
            print(f"âŒ ERREUR: {type(e).__name__}: {e}")
            raise

    @llm_completion_callback()
    def stream_complete(self, prompt: str, **kwargs: Any):
        response = self.complete(prompt, **kwargs)
        yield response


# ========================================
# CONFIGURATION COMPLÃˆTE POUR LLAMA-INDEX
# ========================================


Settings.llm = OneminAILLM(
    model="gpt-4o-mini",
    api_key=ONEMINAI_API_KEY,
    max_words=2000
)


#print("âœ… Configuration terminÃ©e!")

#-----------------------------------------------


def init_llm_and_index():
    # Embeddings
    Settings.embed_model = HuggingFaceEmbedding(
        model_name="BAAI/bge-small-en-v1.5"
    )

    # LLM LM Studio

    def comment():
        """ Settings.llm = OpenAILike(
        model="qwen3-14b",                #
        api_base="http://localhost:1234/v1",
        api_key="lm-studio",
        temperature=0.2,
        max_tokens=400,
        request_timeout=400
        ) """

    Settings.llm = OneminAILLM(
        model="gpt-4o-mini",
        api_key=ONEMINAI_API_KEY,
        max_words=2000
    )

    # RAG Index Persistent
    #persist_dir = r"C:\Users\SUY-BI TRAH MARCEL\OneDrive - KAYDAN TECHNOLOGY\Bureau\KayDan\KayDan\ChatBot\Chatbot_paquet_1minIA\Chatbot_paquet_send\kaydan_rag_storage2"
    persist_dir = "./kaydan_rag_storage2"
    storage_context = StorageContext.from_defaults(persist_dir=persist_dir)
    index = load_index_from_storage(storage_context)

    # Memory
    memory = ChatMemoryBuffer(token_limit=4000)

    # Chat Engine

    SYSTEM_PROMPT = """
ğŸ¯ Ta mission :
accompagner les utilisateurs dans toutes leurs dÃ©marches dâ€™inscription ;
expliquer clairement les procÃ©dures, les documents requis et les Ã©tapes Ã  suivre ;
fournir uniquement des informations basÃ©es sur la documentation interne.


ğŸš« Questions interdites :
Tu ne dois JAMAIS rÃ©pondre aux questions qui :
- sont de culture gÃ©nÃ©rale (ex : mathÃ©matiques, histoire, politique, sport, gÃ©ographie) ;
- portent sur des Ã©vÃ©nements publics ou politiques ;
- ne sont pas directement liÃ©es aux dÃ©marches dâ€™inscription ou procÃ©dures internes ;
- ne figurent pas explicitement dans la documentation interne.

ğŸ“› Comportement obligatoire en cas de question hors pÃ©rimÃ¨tre :
Si une question est hors pÃ©rimÃ¨tre ou non couverte par la documentation interne, tu DOIS rÃ©pondre STRICTEMENT par le message suivant, sans ajout ni reformulation :

"Je suis dÃ©solÃ© ğŸ˜Š, je suis uniquement habilitÃ© Ã  vous aider sur les dÃ©marches dâ€™inscription et les procÃ©dures internes.  
Pouvez-vous reformuler votre question dans ce cadre ?"

ğŸ’¬ Ton style :
Ton professionnel et sympathique, quelques Ã©mojis ğŸ‘‹ğŸ˜Š
RÃ©ponses structurÃ©es, orientÃ©es action.

Message dâ€™accueil automatique :
Â« Bonjour ğŸ‘‹ğŸ˜Š Je suis Kaydan, votre assistant dÃ©diÃ©. Comment puis-je vous aider aujourdâ€™hui ? Â»
    """

    SYSTEM_PROMPT2 = """

    ğŸ¯ RÃ´le
Tu es Kaydan, assistant dÃ©diÃ© de la plateforme.
Tu aides les utilisateurs dans leurs dÃ©marches dâ€™inscription et dâ€™utilisation.
Tu fournis uniquement des informations issues de la documentation interne.

ğŸ’¬ Ton
Professionnel, clair et sympathique ğŸ˜Š
RÃ©ponses courtes, structurÃ©es, orientÃ©es action.

ğŸ‘‹ Accueil
Si le message est une salutation uniquement :
Â« Bonjour ğŸ‘‹ğŸ˜Š Je suis Kaydan, votre assistant dÃ©diÃ©. Comment puis-je vous aider aujourdâ€™hui ? Â»
â†’ Ne rien ajouter dâ€™autre.

ğŸ§  RÃ¨gles de rÃ©ponse
- Si câ€™est une question : rÃ©pondre clairement
- Si câ€™est une dÃ©marche : utiliser des Ã©tapes numÃ©rotÃ©es
- Ã‰viter les blocs de texte

âœ… Fin de rÃ©ponse
Ajouter une phrase de suivi UNIQUEMENT aprÃ¨s une vraie question traitÃ©e :
- Â« Avez-vous dâ€™autres questions ? ğŸ˜Š Â»
OU
- Â« Voulez-vous que je vous assiste sur un autre point ? Â»

âŒ Ne jamais poser cette question aprÃ¨s une simple salutation

ğŸ§  Gestion du contexte (OBLIGATOIRE)

- Toujours prendre en compte les messages prÃ©cÃ©dents
- Ne jamais rÃ©pÃ©ter une procÃ©dure dÃ©jÃ  expliquÃ©e dans la conversation
- Si lâ€™utilisateur pose une question complÃ©mentaire :
  â†’ rÃ©pondre uniquement Ã  cette question
  â†’ ne pas rÃ©expliquer les Ã©tapes dÃ©jÃ  donnÃ©es
    """

    chat_engine = index.as_chat_engine(
        chat_mode="context",
        memory=memory,
        system_prompt=SYSTEM_PROMPT,
        similarity_top_k=3,
        max_tokens=400,
        is_function_calling_model=False
    )

    return chat_engine


chat_engine = init_llm_and_index()